The introduction of interactivity between labeller and learner
=========================================================

This document provides a brief introduction of how labeller and learner communicate with each other. Generally, `labeller` sends a signal to wake up `learner` (an EMR cluster), then `learner` will do its work (including extract features, run model, apply model, and save the sites with high uncertainty (F sites) into __incoming_names__ table in database), which represents one iteration of the active learning loop. When the work is done, `learner` will terminate itself. Once `learner` is terminated, `labeller` will save all new names in __incoming_names__ into __kml_data__ table in database. The system then directs workers to start working on these sites with the highest classification uncertainty (F sites).

The most related scripts includes `generate_consensus_daemon.py`, `consensus_map_generator.R`, `run_learner.py`, `learner_labeller_connection.py`, and `register_f_sites.py`. There are other scripts that connects to this as well, including `select_n_sites.py`, `create_hit_daemon.py`, and `cleanup_absent_worker.py`.

The general workflow is shown as follow:

![](interactivity.png?raw=true)

Reminder of different types of sites
------------------------------------

-   F sites: sites with high uncertainty generated by `learner`.
-   N sites: normal sites to keep the worker busy.
-   Q sites: sites for qualification
-   I sites: special Q sites for the qualification test before a worker start to work.

Daemon `generate_consensus_daemon.py`
-------------------------------------

It is the major script to connect `labeller` and `learner`, which is an alive daemon in labeller. It is watching the __incoming_names__ table and __kml_data__ table in our database.

There is an relationship between these two tables. All the sites in __incoming_names__ are in __kml_data__ as F sites. The __incoming_names__ is the container to receive sites getting from `learner`, but also the launcher of a signal to trigger `learner`.

### Generate consensus maps

In __incoming_names__, `processed = FALSE` means this site is not finished by the workers yet. But when `mapped_count = labellers_needed` in __kml_data__, it means the site is finished by the workers. So `generate_consensus_daemon.py` will call the `consensus_map_generator.R` to generate consensus map for this site, saving an image into S3 bucket (activelabeller/labels). Once it is done, `generate_consensus_daemon.py` will change the _processed_ to "TRUE" for this site in __incoming_names__. This is a loop for one site.

### Trigger `learner`

After all sites in __incoming_names__ finish the loop above, `generate_consensus_daemon.py` will call `run_learner.py`. It is a script to run `Terraform` which is a binary to create an EMR cluster on AWS. `run_learner.py` will get back the id of this EMR cluster when it is created successully.

### `learner`

The `learner` is a self-terminated EMR cluster. Once it is created, it will download and run the related scripts from S3 bucket (`learner_labeller_connection.py` for example, only mention it because this is the only script used for testing interactivity). As designed, `learner` will finish a Ramdom Forest model, apply this model to some new sites, then get a bunch of sites with highest uncertainty and save them back to __incoming_names__ table. After all these are done, `learner` will terminate itself. This is an iteration for active learning.

### Getting sites gived back from `learner`

As mentioned before, when `learner` is created, we get back the id of the cluster. So after `generate_consensus_daemon.py` triggers the `learner`, it keeps watching the state of this cluster using the id. After the state of this cluser becomes `TERMINATED`, `generate_consensus_daemon.py` then call `register_f_sites.py` to save all the new sites in __incoming_names__ table into __kml_data__ table as F sites.

So far, one bout of interactivity is finished.

Daemon `select_n_sites.py`
--------------------------

Because the `learner` could spend a long time to run the model, the system could be out of F sites for a while. When this happens, the system could give the workers N sites to work on. So we should make sure there are always N sites there to keep the workers busy. When the system is out of N sites, `select_n_sites.py` will grab a bunch of sites from `master_grid` table in database and insert them into __kml_data__ as new N sites.

Daemon `create_hit_daemon.py` and `cleanup_absent_worker.py`
------------------------------------------------------------

These two daemons are working to create assignments for the workers and keep the system clean.
